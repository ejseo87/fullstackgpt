{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Any, Type\n",
    "from langchain.utilities import WikipediaAPIWrapper\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.tools import DuckDuckGoSearchResults\n",
    "from langchain.tools import WikipediaQueryRun\n",
    "\n",
    "\n",
    "def wikipedia_search(inputs):\n",
    "  query = inputs[\"query\"]\n",
    "  wiki = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(top_k_results=5))\n",
    "  return wiki.run(query)\n",
    "\n",
    "def duckduckgo_search(inputs):\n",
    "  query = inputs[\"query\"]\n",
    "  search = DuckDuckGoSearchResults()\n",
    "  return search.run(query)\n",
    "\n",
    "def web_scraping(inputs):\n",
    "  url = inputs[\"url\"]\n",
    "  loader = WebBaseLoader([url])\n",
    "  docs = loader.load()\n",
    "  text = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "  return text\n",
    "\n",
    "def save_to_text(inputs):\n",
    "  filename = inputs[\"filename\"]\n",
    "  text = inputs[\"text\"]\n",
    "  os.makedirs(\"./assistants_research_results\", exist_ok=True)\n",
    "  if not filename.endswith('.txt'):\n",
    "      filename += '.txt'\n",
    "  file_path = os.path.join(\"./assistants_research_results\", filename)\n",
    "  with open(file_path, 'w', encoding='utf-8') as f:\n",
    "      f.write(text)\n",
    "  return f\"Research results saved to {file_path}\"  \n",
    "\n",
    "functions_map = {\n",
    "    \"wikipedia_search\": wikipedia_search,\n",
    "    \"duckduckgo_search\": duckduckgo_search,\n",
    "    \"web_scraping\": web_scraping,\n",
    "    \"save_to_text\": save_to_text,\n",
    "}\n",
    "\n",
    "functions = [\n",
    "  {\n",
    "    \"type\": \"function\",\n",
    "      \"function\": {\n",
    "          \"name\": \"wikipedia_search\",\n",
    "          \"description\": \"Use this tool to perform searches on Wikipedia. It takes a query as an argument. Example query: 'Artificial Intelligence'\",\n",
    "          \"parameters\": {\n",
    "              \"type\": \"object\",\n",
    "              \"properties\": {\n",
    "                  \"query\": {\n",
    "                      \"type\": \"string\",\n",
    "                      \"description\": \"The query you will search for on Wikipedia\",\n",
    "                  }\n",
    "              },\n",
    "              \"required\": [\"query\"],\n",
    "          },\n",
    "      },\n",
    "\n",
    "  },\n",
    "  {\n",
    "      \"type\": \"function\",\n",
    "      \"function\": {\n",
    "          \"name\": \"duckduckgo_search\",\n",
    "          \"description\": \"Use this tool to perform web searches using the DuckDuckGo search engine. It takes a query as an argument. Example query: 'Latest technology news'\",\n",
    "          \"parameters\": {\n",
    "              \"type\": \"object\",\n",
    "              \"properties\": {\n",
    "                  \"query\": {\n",
    "                      \"type\": \"string\",\n",
    "                      \"description\": \"The query you will search for\",\n",
    "                  }\n",
    "              },\n",
    "              \"required\": [\"query\"],\n",
    "          },\n",
    "      },\n",
    "  },\n",
    "  {\n",
    "    \"type\": \"function\",\n",
    "      \"function\": {\n",
    "          \"name\": \"web_scraping\",\n",
    "          \"description\": \"If you found the website link in DuckDuckGo, Use this to get the content of the link for my research.\",\n",
    "          \"parameters\": {\n",
    "              \"type\": \"object\",\n",
    "              \"properties\": {\n",
    "                  \"url\": {\n",
    "                      \"type\": \"string\",\n",
    "                      \"description\": \"The URL of the website you want to scrape\",\n",
    "                  }\n",
    "              },\n",
    "              \"required\": [\"url\"],\n",
    "          },\n",
    "      },\n",
    "\n",
    "  },\n",
    "  {\n",
    "      \"type\": \"function\",\n",
    "      \"function\": {\n",
    "          \"name\": \"save_to_text\",\n",
    "          \"description\": \"Use this tool to save the content as a .txt file.\",\n",
    "          \"parameters\": {\n",
    "              \"type\": \"object\",\n",
    "              \"properties\": {\n",
    "                  \"filename\": {\n",
    "                      \"type\": \"string\",\n",
    "                      \"description\": \"a name of the file you will save the research results\",\n",
    "                  },\n",
    "                  \"text\": {\n",
    "                      \"type\": \"string\",\n",
    "                      \"description\": \"The text you will save to a file.\",\n",
    "                  }\n",
    "              },\n",
    "              \"required\": [\"text\"],\n",
    "          },\n",
    "      },\n",
    "\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "assistant_id = \"asst_Non2tRgu3rvBrRrnS8qHGRny\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Thread(id='thread_anmnLZ1VT6qonsQEg1wzsxeo', created_at=1746893986, metadata={}, object='thread', tool_resources=ToolResources(code_interpreter=None, file_search=None))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thread = client.beta.threads.create(\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\":\"user\",\n",
    "      \"content\": \"Research about Trump Tariff on China in 2025\",\n",
    "    }\n",
    "  ]\n",
    ")\n",
    "thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def get_run(run_id, thread_id):\n",
    "    return client.beta.threads.runs.retrieve(\n",
    "        run_id=run_id,\n",
    "        thread_id=thread_id,\n",
    "    )\n",
    "\n",
    "\n",
    "def send_message(thread_id, content):\n",
    "    return client.beta.threads.messages.create(\n",
    "        thread_id=thread_id, role=\"user\", content=content\n",
    "    )\n",
    "\n",
    "\n",
    "def get_messages(thread_id):\n",
    "    messages = client.beta.threads.messages.list(thread_id=thread_id)\n",
    "    messages = list(messages)\n",
    "    messages.reverse()\n",
    "    for message in messages:\n",
    "        print(f\"{message.role}: {message.content[0].text.value}\")\n",
    "\n",
    "\n",
    "def get_tool_outputs(run_id, thread_id):\n",
    "    run = get_run(run_id, thread.id)\n",
    "    outputs = []\n",
    "    for action in run.required_action.submit_tool_outputs.tool_calls:\n",
    "        action_id = action.id\n",
    "        function = action.function\n",
    "        print(f\"Calling function: {function.name} with arg {function.arguments}\")\n",
    "        outputs.append(\n",
    "            {\n",
    "                \"output\": functions_map[function.name](json.loads(function.arguments)),\n",
    "                \"tool_call_id\": action_id,\n",
    "            }\n",
    "        )\n",
    "    return outputs\n",
    "\n",
    "\n",
    "def submit_tool_outputs(run_id, thread_id):\n",
    "    outpus = get_tool_outputs(run_id, thread_id)\n",
    "    return client.beta.threads.runs.submit_tool_outputs(\n",
    "        run_id=run_id, thread_id=thread_id, tool_outputs=outpus\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Run(id='run_w98BL7AIU9go000WGLm7dwAT', assistant_id='asst_Non2tRgu3rvBrRrnS8qHGRny', cancelled_at=None, completed_at=None, created_at=1746893996, expires_at=1746894596, failed_at=None, incomplete_details=None, instructions='\\n        You are a research expert.\\n\\n        Your task is to use Wikipedia or DuckDuckGo to gather comprehensive and accurate information about the query provided. \\n\\n        When you find a relevant website through DuckDuckGo, you must scrape the content from that website. Use this scraped content to thoroughly research and formulate a detailed answer to the question. \\n\\n        Combine information from Wikipedia, DuckDuckGo searches, and any relevant websites you find. Ensure that the final answer is well-organized and detailed, and include citations with links (URLs) for all sources used.\\n\\n        Your research should be saved to a .txt file, and the content should match the detailed findings provided. Make sure to include all sources and relevant information.\\n\\n        The information from Wikipedia must be included.\\n\\n        Ensure that the final .txt file contains detailed information, all relevant sources, and citations.\\n        ', last_error=None, max_completion_tokens=None, max_prompt_tokens=None, metadata={}, model='gpt-3.5-turbo-1106', object='thread.run', parallel_tool_calls=True, required_action=None, response_format='auto', started_at=None, status='queued', thread_id='thread_anmnLZ1VT6qonsQEg1wzsxeo', tool_choice='auto', tools=[FunctionTool(function=FunctionDefinition(name='duckduckgo_search', description=\"Use this tool to perform web searches using the DuckDuckGo search engine. It takes a query as an argument. Example query: 'Latest technology news'\", parameters={'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'The query you will search for'}}, 'required': ['query']}, strict=False), type='function'), FunctionTool(function=FunctionDefinition(name='wikipedia_search', description=\"Use this tool to perform searches on Wikipedia. It takes a query as an argument. Example query: 'Artificial Intelligence'\", parameters={'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'The query you will search for on Wikipedia'}}, 'required': ['query']}, strict=False), type='function'), FunctionTool(function=FunctionDefinition(name='web_scraping', description='If you found the website link in DuckDuckGo, Use this to get the content of the link for my research.', parameters={'type': 'object', 'properties': {'url': {'type': 'string', 'description': 'The URL of the website you want to scrape'}}, 'required': ['url']}, strict=False), type='function'), FunctionTool(function=FunctionDefinition(name='save_to_text', description='Use this tool to save the content as a .txt file.', parameters={'type': 'object', 'properties': {'filename': {'type': 'string', 'description': 'a name of the file you will save the research results'}, 'text': {'type': 'string', 'description': 'The text you will save to a file.'}}, 'required': ['text']}, strict=False), type='function')], truncation_strategy=TruncationStrategy(type='auto', last_messages=None), usage=None, temperature=1.0, top_p=1.0, tool_resources={}, reasoning_effort=None)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant_id,\n",
    ")\n",
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'completed'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_run(run.id, thread.id).status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Run(id='run_xlGmogR5EGMUZdFCGMil7wke', assistant_id='asst_Non2tRgu3rvBrRrnS8qHGRny', cancelled_at=None, completed_at=1746893396, created_at=1746893270, expires_at=None, failed_at=None, incomplete_details=None, instructions='\\n        You are a research expert.\\n\\n        Your task is to use Wikipedia or DuckDuckGo to gather comprehensive and accurate information about the query provided. \\n\\n        When you find a relevant website through DuckDuckGo, you must scrape the content from that website. Use this scraped content to thoroughly research and formulate a detailed answer to the question. \\n\\n        Combine information from Wikipedia, DuckDuckGo searches, and any relevant websites you find. Ensure that the final answer is well-organized and detailed, and include citations with links (URLs) for all sources used.\\n\\n        Your research should be saved to a .txt file, and the content should match the detailed findings provided. Make sure to include all sources and relevant information.\\n\\n        The information from Wikipedia must be included.\\n\\n        Ensure that the final .txt file contains detailed information, all relevant sources, and citations.\\n        ', last_error=None, max_completion_tokens=None, max_prompt_tokens=None, metadata={}, model='gpt-3.5-turbo-1106', object='thread.run', parallel_tool_calls=True, required_action=None, response_format='auto', started_at=1746893391, status='completed', thread_id='thread_FC18dLNHWyC7xFQirc1iEiWS', tool_choice='auto', tools=[FunctionTool(function=FunctionDefinition(name='duckduckgo_search', description=\"Use this tool to perform web searches using the DuckDuckGo search engine. It takes a query as an argument. Example query: 'Latest technology news'\", parameters={'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'The query you will search for'}}, 'required': ['query']}, strict=False), type='function'), FunctionTool(function=FunctionDefinition(name='wikipedia_search', description=\"Use this tool to perform searches on Wikipedia. It takes a query as an argument. Example query: 'Artificial Intelligence'\", parameters={'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'The query you will search for on Wikipedia'}}, 'required': ['query']}, strict=False), type='function'), FunctionTool(function=FunctionDefinition(name='web_scraping', description='If you found the website link in DuckDuckGo, Use this to get the content of the link for my research.', parameters={'type': 'object', 'properties': {'url': {'type': 'string', 'description': 'The URL of the website you want to scrape'}}, 'required': ['url']}, strict=False), type='function'), FunctionTool(function=FunctionDefinition(name='save_to_text', description='Use this tool to save the content as a .txt file.', parameters={'type': 'object', 'properties': {'filename': {'type': 'string', 'description': 'a name of the file you will save the research results'}, 'text': {'type': 'string', 'description': 'The text you will save to a file.'}}, 'required': ['text']}, strict=False), type='function')], truncation_strategy=TruncationStrategy(type='auto', last_messages=None), usage=Usage(completion_tokens=678, prompt_tokens=2551, total_tokens=3229, prompt_token_details={'cached_tokens': 0}, completion_tokens_details={'reasoning_tokens': 0}), temperature=1.0, top_p=1.0, tool_resources={}, reasoning_effort=None)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_run(run.id, thread.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: Research about Trump Tariff on China in 2025\n"
     ]
    }
   ],
   "source": [
    "get_messages(thread.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling function: wikipedia_search with arg {\"query\": \"Trump Tariff on China\"}\n",
      "Calling function: duckduckgo_search with arg {\"query\": \"Trump Tariff on China 2025\"}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Run(id='run_w98BL7AIU9go000WGLm7dwAT', assistant_id='asst_Non2tRgu3rvBrRrnS8qHGRny', cancelled_at=None, completed_at=None, created_at=1746893996, expires_at=1746894596, failed_at=None, incomplete_details=None, instructions='\\n        You are a research expert.\\n\\n        Your task is to use Wikipedia or DuckDuckGo to gather comprehensive and accurate information about the query provided. \\n\\n        When you find a relevant website through DuckDuckGo, you must scrape the content from that website. Use this scraped content to thoroughly research and formulate a detailed answer to the question. \\n\\n        Combine information from Wikipedia, DuckDuckGo searches, and any relevant websites you find. Ensure that the final answer is well-organized and detailed, and include citations with links (URLs) for all sources used.\\n\\n        Your research should be saved to a .txt file, and the content should match the detailed findings provided. Make sure to include all sources and relevant information.\\n\\n        The information from Wikipedia must be included.\\n\\n        Ensure that the final .txt file contains detailed information, all relevant sources, and citations.\\n        ', last_error=None, max_completion_tokens=None, max_prompt_tokens=None, metadata={}, model='gpt-3.5-turbo-1106', object='thread.run', parallel_tool_calls=True, required_action=None, response_format='auto', started_at=1746893997, status='queued', thread_id='thread_anmnLZ1VT6qonsQEg1wzsxeo', tool_choice='auto', tools=[FunctionTool(function=FunctionDefinition(name='duckduckgo_search', description=\"Use this tool to perform web searches using the DuckDuckGo search engine. It takes a query as an argument. Example query: 'Latest technology news'\", parameters={'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'The query you will search for'}}, 'required': ['query']}, strict=False), type='function'), FunctionTool(function=FunctionDefinition(name='wikipedia_search', description=\"Use this tool to perform searches on Wikipedia. It takes a query as an argument. Example query: 'Artificial Intelligence'\", parameters={'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'The query you will search for on Wikipedia'}}, 'required': ['query']}, strict=False), type='function'), FunctionTool(function=FunctionDefinition(name='web_scraping', description='If you found the website link in DuckDuckGo, Use this to get the content of the link for my research.', parameters={'type': 'object', 'properties': {'url': {'type': 'string', 'description': 'The URL of the website you want to scrape'}}, 'required': ['url']}, strict=False), type='function'), FunctionTool(function=FunctionDefinition(name='save_to_text', description='Use this tool to save the content as a .txt file.', parameters={'type': 'object', 'properties': {'filename': {'type': 'string', 'description': 'a name of the file you will save the research results'}, 'text': {'type': 'string', 'description': 'The text you will save to a file.'}}, 'required': ['text']}, strict=False), type='function')], truncation_strategy=TruncationStrategy(type='auto', last_messages=None), usage=None, temperature=1.0, top_p=1.0, tool_resources={}, reasoning_effort=None)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_tool_outputs(run.id, thread.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fullstackgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
