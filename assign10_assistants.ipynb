{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Any, Type\n",
    "from langchain.utilities import WikipediaAPIWrapper\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.tools import DuckDuckGoSearchResults\n",
    "from langchain.tools import WikipediaQueryRun\n",
    "\n",
    "\n",
    "def wikipedia_search(inputs):\n",
    "  query = inputs[\"query\"]\n",
    "  wiki = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(top_k_results=5))\n",
    "  return wiki.run(query)\n",
    "\n",
    "def duckduckgo_search(inputs):\n",
    "  query = inputs[\"query\"]\n",
    "  search = DuckDuckGoSearchResults()\n",
    "  return search.run(query)\n",
    "\n",
    "def web_scraping(inputs):\n",
    "  url = inputs[\"url\"]\n",
    "  loader = WebBaseLoader([url])\n",
    "  docs = loader.load()\n",
    "  text = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "  return text\n",
    "\n",
    "def save_to_text(inputs):\n",
    "  filename = inputs[\"filename\"]\n",
    "  text = inputs[\"text\"]\n",
    "  os.makedirs(\"./assistants_research_results\", exist_ok=True)\n",
    "  if not filename.endswith('.txt'):\n",
    "      filename += '.txt'\n",
    "  file_path = os.path.join(\"./assistants_research_results\", filename)\n",
    "  with open(file_path, 'w', encoding='utf-8') as f:\n",
    "      f.write(text)\n",
    "  return f\"Research results saved to {file_path}\"  \n",
    "\n",
    "functions_map = {\n",
    "    \"wikipedia_search\": wikipedia_search,\n",
    "    \"duckduckgo_search\": duckduckgo_search,\n",
    "    \"web_scraping\": web_scraping,\n",
    "    \"save_to_text\": save_to_text,\n",
    "}\n",
    "\n",
    "functions = [\n",
    "  {\n",
    "    \"type\": \"function\",\n",
    "      \"function\": {\n",
    "          \"name\": \"wikipedia_search\",\n",
    "          \"description\": \"Use this tool to perform searches on Wikipedia. It takes a query as an argument. Example query: 'Artificial Intelligence'\",\n",
    "          \"parameters\": {\n",
    "              \"type\": \"object\",\n",
    "              \"properties\": {\n",
    "                  \"query\": {\n",
    "                      \"type\": \"string\",\n",
    "                      \"description\": \"The query you will search for on Wikipedia\",\n",
    "                  }\n",
    "              },\n",
    "              \"required\": [\"query\"],\n",
    "          },\n",
    "      },\n",
    "\n",
    "  },\n",
    "  {\n",
    "      \"type\": \"function\",\n",
    "      \"function\": {\n",
    "          \"name\": \"duckduckgo_search\",\n",
    "          \"description\": \"Use this tool to perform web searches using the DuckDuckGo search engine. It takes a query as an argument. Example query: 'Latest technology news'\",\n",
    "          \"parameters\": {\n",
    "              \"type\": \"object\",\n",
    "              \"properties\": {\n",
    "                  \"query\": {\n",
    "                      \"type\": \"string\",\n",
    "                      \"description\": \"The query you will search for\",\n",
    "                  }\n",
    "              },\n",
    "              \"required\": [\"query\"],\n",
    "          },\n",
    "      },\n",
    "  },\n",
    "  {\n",
    "    \"type\": \"function\",\n",
    "      \"function\": {\n",
    "          \"name\": \"web_scraping\",\n",
    "          \"description\": \"If you found the website link in DuckDuckGo, Use this to get the content of the link for my research.\",\n",
    "          \"parameters\": {\n",
    "              \"type\": \"object\",\n",
    "              \"properties\": {\n",
    "                  \"url\": {\n",
    "                      \"type\": \"string\",\n",
    "                      \"description\": \"The URL of the website you want to scrape\",\n",
    "                  }\n",
    "              },\n",
    "              \"required\": [\"url\"],\n",
    "          },\n",
    "      },\n",
    "\n",
    "  },\n",
    "  {\n",
    "      \"type\": \"function\",\n",
    "      \"function\": {\n",
    "          \"name\": \"save_to_text\",\n",
    "          \"description\": \"Use this tool to save the content as a .txt file.\",\n",
    "          \"parameters\": {\n",
    "              \"type\": \"object\",\n",
    "              \"properties\": {\n",
    "                  \"filename\": {\n",
    "                      \"type\": \"string\",\n",
    "                      \"description\": \"a name of the file you will save the research results\",\n",
    "                  },\n",
    "                  \"text\": {\n",
    "                      \"type\": \"string\",\n",
    "                      \"description\": \"The text you will save to a file.\",\n",
    "                  }\n",
    "              },\n",
    "              \"required\": [\"text\"],\n",
    "          },\n",
    "      },\n",
    "\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "assistant_id = \"asst_Non2tRgu3rvBrRrnS8qHGRny\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Thread(id='thread_anmnLZ1VT6qonsQEg1wzsxeo', created_at=1746893986, metadata={}, object='thread', tool_resources=ToolResources(code_interpreter=None, file_search=None))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thread = client.beta.threads.create(\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\":\"user\",\n",
    "      \"content\": \"Research about Trump Tariff on China in 2025\",\n",
    "    }\n",
    "  ]\n",
    ")\n",
    "thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def get_run(run_id, thread_id):\n",
    "    return client.beta.threads.runs.retrieve(\n",
    "        run_id=run_id,\n",
    "        thread_id=thread_id,\n",
    "    )\n",
    "\n",
    "\n",
    "def send_message(thread_id, content):\n",
    "    return client.beta.threads.messages.create(\n",
    "        thread_id=thread_id, role=\"user\", content=content\n",
    "    )\n",
    "\n",
    "\n",
    "def get_messages(thread_id):\n",
    "    messages = client.beta.threads.messages.list(thread_id=thread_id)\n",
    "    messages = list(messages)\n",
    "    messages.reverse()\n",
    "    for message in messages:\n",
    "        print(f\"{message.role}: {message.content[0].text.value}\")\n",
    "\n",
    "\n",
    "def get_tool_outputs(run_id, thread_id):\n",
    "    run = get_run(run_id, thread.id)\n",
    "    outputs = []\n",
    "    for action in run.required_action.submit_tool_outputs.tool_calls:\n",
    "        action_id = action.id\n",
    "        function = action.function\n",
    "        print(f\"Calling function: {function.name} with arg {function.arguments}\")\n",
    "        outputs.append(\n",
    "            {\n",
    "                \"output\": functions_map[function.name](json.loads(function.arguments)),\n",
    "                \"tool_call_id\": action_id,\n",
    "            }\n",
    "        )\n",
    "    return outputs\n",
    "\n",
    "\n",
    "def submit_tool_outputs(run_id, thread_id):\n",
    "    outpus = get_tool_outputs(run_id, thread_id)\n",
    "    return client.beta.threads.runs.submit_tool_outputs(\n",
    "        run_id=run_id, thread_id=thread_id, tool_outputs=outpus\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Run(id='run_w98BL7AIU9go000WGLm7dwAT', assistant_id='asst_Non2tRgu3rvBrRrnS8qHGRny', cancelled_at=None, completed_at=None, created_at=1746893996, expires_at=1746894596, failed_at=None, incomplete_details=None, instructions='\\n        You are a research expert.\\n\\n        Your task is to use Wikipedia or DuckDuckGo to gather comprehensive and accurate information about the query provided. \\n\\n        When you find a relevant website through DuckDuckGo, you must scrape the content from that website. Use this scraped content to thoroughly research and formulate a detailed answer to the question. \\n\\n        Combine information from Wikipedia, DuckDuckGo searches, and any relevant websites you find. Ensure that the final answer is well-organized and detailed, and include citations with links (URLs) for all sources used.\\n\\n        Your research should be saved to a .txt file, and the content should match the detailed findings provided. Make sure to include all sources and relevant information.\\n\\n        The information from Wikipedia must be included.\\n\\n        Ensure that the final .txt file contains detailed information, all relevant sources, and citations.\\n        ', last_error=None, max_completion_tokens=None, max_prompt_tokens=None, metadata={}, model='gpt-3.5-turbo-1106', object='thread.run', parallel_tool_calls=True, required_action=None, response_format='auto', started_at=None, status='queued', thread_id='thread_anmnLZ1VT6qonsQEg1wzsxeo', tool_choice='auto', tools=[FunctionTool(function=FunctionDefinition(name='duckduckgo_search', description=\"Use this tool to perform web searches using the DuckDuckGo search engine. It takes a query as an argument. Example query: 'Latest technology news'\", parameters={'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'The query you will search for'}}, 'required': ['query']}, strict=False), type='function'), FunctionTool(function=FunctionDefinition(name='wikipedia_search', description=\"Use this tool to perform searches on Wikipedia. It takes a query as an argument. Example query: 'Artificial Intelligence'\", parameters={'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'The query you will search for on Wikipedia'}}, 'required': ['query']}, strict=False), type='function'), FunctionTool(function=FunctionDefinition(name='web_scraping', description='If you found the website link in DuckDuckGo, Use this to get the content of the link for my research.', parameters={'type': 'object', 'properties': {'url': {'type': 'string', 'description': 'The URL of the website you want to scrape'}}, 'required': ['url']}, strict=False), type='function'), FunctionTool(function=FunctionDefinition(name='save_to_text', description='Use this tool to save the content as a .txt file.', parameters={'type': 'object', 'properties': {'filename': {'type': 'string', 'description': 'a name of the file you will save the research results'}, 'text': {'type': 'string', 'description': 'The text you will save to a file.'}}, 'required': ['text']}, strict=False), type='function')], truncation_strategy=TruncationStrategy(type='auto', last_messages=None), usage=None, temperature=1.0, top_p=1.0, tool_resources={}, reasoning_effort=None)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant_id,\n",
    ")\n",
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'completed'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_run(run.id, thread.id).status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Run(id='run_xlGmogR5EGMUZdFCGMil7wke', assistant_id='asst_Non2tRgu3rvBrRrnS8qHGRny', cancelled_at=None, completed_at=1746893396, created_at=1746893270, expires_at=None, failed_at=None, incomplete_details=None, instructions='\\n        You are a research expert.\\n\\n        Your task is to use Wikipedia or DuckDuckGo to gather comprehensive and accurate information about the query provided. \\n\\n        When you find a relevant website through DuckDuckGo, you must scrape the content from that website. Use this scraped content to thoroughly research and formulate a detailed answer to the question. \\n\\n        Combine information from Wikipedia, DuckDuckGo searches, and any relevant websites you find. Ensure that the final answer is well-organized and detailed, and include citations with links (URLs) for all sources used.\\n\\n        Your research should be saved to a .txt file, and the content should match the detailed findings provided. Make sure to include all sources and relevant information.\\n\\n        The information from Wikipedia must be included.\\n\\n        Ensure that the final .txt file contains detailed information, all relevant sources, and citations.\\n        ', last_error=None, max_completion_tokens=None, max_prompt_tokens=None, metadata={}, model='gpt-3.5-turbo-1106', object='thread.run', parallel_tool_calls=True, required_action=None, response_format='auto', started_at=1746893391, status='completed', thread_id='thread_FC18dLNHWyC7xFQirc1iEiWS', tool_choice='auto', tools=[FunctionTool(function=FunctionDefinition(name='duckduckgo_search', description=\"Use this tool to perform web searches using the DuckDuckGo search engine. It takes a query as an argument. Example query: 'Latest technology news'\", parameters={'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'The query you will search for'}}, 'required': ['query']}, strict=False), type='function'), FunctionTool(function=FunctionDefinition(name='wikipedia_search', description=\"Use this tool to perform searches on Wikipedia. It takes a query as an argument. Example query: 'Artificial Intelligence'\", parameters={'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'The query you will search for on Wikipedia'}}, 'required': ['query']}, strict=False), type='function'), FunctionTool(function=FunctionDefinition(name='web_scraping', description='If you found the website link in DuckDuckGo, Use this to get the content of the link for my research.', parameters={'type': 'object', 'properties': {'url': {'type': 'string', 'description': 'The URL of the website you want to scrape'}}, 'required': ['url']}, strict=False), type='function'), FunctionTool(function=FunctionDefinition(name='save_to_text', description='Use this tool to save the content as a .txt file.', parameters={'type': 'object', 'properties': {'filename': {'type': 'string', 'description': 'a name of the file you will save the research results'}, 'text': {'type': 'string', 'description': 'The text you will save to a file.'}}, 'required': ['text']}, strict=False), type='function')], truncation_strategy=TruncationStrategy(type='auto', last_messages=None), usage=Usage(completion_tokens=678, prompt_tokens=2551, total_tokens=3229, prompt_token_details={'cached_tokens': 0}, completion_tokens_details={'reasoning_tokens': 0}), temperature=1.0, top_p=1.0, tool_resources={}, reasoning_effort=None)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_run(run.id, thread.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: Research about Trump Tariff on China in 2025\n",
      "assistant: The Trump Tariffs on China refer to the trade war initiated by the administration of President Donald Trump against China. The tariffs were a part of a protectionist trade policy aimed at addressing trade imbalances and protecting American industries. Here's a detailed summary of the information gathered:\n",
      "\n",
      "### Wikipedia Information:\n",
      "According to the information on the Wikipedia page about \"Tariffs in the first Trump administration,\" the tariffs during the first presidency of Donald Trump involved protectionist trade initiatives against China and other countries. It primarily involved tariffs on foreign imports, with the imposition of tariffs on solar panels, washing machines, steel, aluminum, and other goods from various countries. These tariffs led to retaliatory measures by trading partners, including China, India, and Canada. The impact of the tariffs was significant, with adverse effects on U.S. GDP, real income, and political dynamics. It also mentions that President Trump's successor, President Biden, kept most of the tariffs in place.\n",
      "\n",
      "During his second presidency, President Donald Trump enacted a series of steep protective tariffs affecting nearly all goods imported into the United States, raising the average effective US tariff rate to an estimated 27%, the highest level in over a century. The trade war with China was escalated during this time.\n",
      "\n",
      "### DuckDuckGo Search Results:\n",
      "The DuckDuckGo search results provided further insights into the tariffs on China in 2025. President Donald Trump voiced a willingness to ease tariffs on China during trade negotiations. It was mentioned that tariffs on Chinese imports to the United States would eventually be lowered, and that in 2025, Trump's tariffs would increase federal tax revenues by $163.1 billion. Furthermore, China unveiled retaliatory tariffs of 84% on imports of U.S. goods, matching additional tariffs imposed by President Trump.\n",
      "\n",
      "### Additional Findings:\n",
      "I found a variety of news articles and websites discussing the increase in tariffs on Chinese imports and the retaliatory measures taken by China. One article from abcnews.go.com mentions an intention to ease tariffs on China, while another from cnn.com talks about potential tariff reductions and increases in tax revenues from tariffs.\n",
      "\n",
      "### Conclusion:\n",
      "The Trump Tariffs on China during 2025 involved the continuation of protectionist trade policies and escalations of the trade war between the United States and China. The impact of these tariffs was significant, marked by increased tax revenues, retaliatory measures by China, and discussions about easing tariffs during trade negotiations.\n",
      "\n",
      "For a more comprehensive understanding of the specific tariff rates, affected sectors, and latest updates on this topic, a detailed analysis of official government sources, economic reports, and trade policy announcements would be beneficial.\n",
      "\n",
      "Sources:\n",
      "1. Wikipedia: [Tariffs in the first Trump administration](https://en.wikipedia.org/wiki/Tariffs_in_the_first_Trump_administration)\n",
      "2. DuckDuckGo: [Trump floats lower tariffs on China](https://abcnews.go.com/US/trump-floats-lower-tariffs-china-prices/story?id=121636516) \n",
      "3. DuckDuckGo: [Trump says he will lower tariffs on China 'at some point'](https://www.cnn.com/2025/05/05/business/trump-lower-tariffs-on-china-intl-hnk)\n",
      "4. Tax Foundation: [The Economic Impact of the Trump Trade War](https://taxfoundation.org/research/all/federal/trump-tariffs-trade-war/)\n",
      "5. CNN Business: [China announces 84% tariffs on US goods in showdown with Trump](https://edition.cnn.com/2025/04/09/business/china-us-tariffs-retaliation-hnk-intl/index.html)\n"
     ]
    }
   ],
   "source": [
    "get_messages(thread.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling function: wikipedia_search with arg {\"query\": \"Trump Tariff on China\"}\n",
      "Calling function: duckduckgo_search with arg {\"query\": \"Trump Tariff on China 2025\"}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Run(id='run_w98BL7AIU9go000WGLm7dwAT', assistant_id='asst_Non2tRgu3rvBrRrnS8qHGRny', cancelled_at=None, completed_at=None, created_at=1746893996, expires_at=1746894596, failed_at=None, incomplete_details=None, instructions='\\n        You are a research expert.\\n\\n        Your task is to use Wikipedia or DuckDuckGo to gather comprehensive and accurate information about the query provided. \\n\\n        When you find a relevant website through DuckDuckGo, you must scrape the content from that website. Use this scraped content to thoroughly research and formulate a detailed answer to the question. \\n\\n        Combine information from Wikipedia, DuckDuckGo searches, and any relevant websites you find. Ensure that the final answer is well-organized and detailed, and include citations with links (URLs) for all sources used.\\n\\n        Your research should be saved to a .txt file, and the content should match the detailed findings provided. Make sure to include all sources and relevant information.\\n\\n        The information from Wikipedia must be included.\\n\\n        Ensure that the final .txt file contains detailed information, all relevant sources, and citations.\\n        ', last_error=None, max_completion_tokens=None, max_prompt_tokens=None, metadata={}, model='gpt-3.5-turbo-1106', object='thread.run', parallel_tool_calls=True, required_action=None, response_format='auto', started_at=1746893997, status='queued', thread_id='thread_anmnLZ1VT6qonsQEg1wzsxeo', tool_choice='auto', tools=[FunctionTool(function=FunctionDefinition(name='duckduckgo_search', description=\"Use this tool to perform web searches using the DuckDuckGo search engine. It takes a query as an argument. Example query: 'Latest technology news'\", parameters={'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'The query you will search for'}}, 'required': ['query']}, strict=False), type='function'), FunctionTool(function=FunctionDefinition(name='wikipedia_search', description=\"Use this tool to perform searches on Wikipedia. It takes a query as an argument. Example query: 'Artificial Intelligence'\", parameters={'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'The query you will search for on Wikipedia'}}, 'required': ['query']}, strict=False), type='function'), FunctionTool(function=FunctionDefinition(name='web_scraping', description='If you found the website link in DuckDuckGo, Use this to get the content of the link for my research.', parameters={'type': 'object', 'properties': {'url': {'type': 'string', 'description': 'The URL of the website you want to scrape'}}, 'required': ['url']}, strict=False), type='function'), FunctionTool(function=FunctionDefinition(name='save_to_text', description='Use this tool to save the content as a .txt file.', parameters={'type': 'object', 'properties': {'filename': {'type': 'string', 'description': 'a name of the file you will save the research results'}, 'text': {'type': 'string', 'description': 'The text you will save to a file.'}}, 'required': ['text']}, strict=False), type='function')], truncation_strategy=TruncationStrategy(type='auto', last_messages=None), usage=None, temperature=1.0, top_p=1.0, tool_resources={}, reasoning_effort=None)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_tool_outputs(run.id, thread.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fullstackgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
