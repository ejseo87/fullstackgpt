{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Any, Type\n",
    "from langchain.utilities import WikipediaAPIWrapper\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.tools import DuckDuckGoSearchResults\n",
    "from langchain.tools import WikipediaQueryRun\n",
    "\n",
    "def duckduckgo_search(inputs):\n",
    "  query = inputs[\"query\"]\n",
    "  search = DuckDuckGoSearchResults()\n",
    "  return search.run(query)\n",
    "\n",
    "def wikipedia_search(inputs):\n",
    "  query = inputs[\"query\"]\n",
    "  wiki = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(top_k_results=5))\n",
    "  return wiki.run(query)\n",
    "\n",
    "def web_scraping(inputs):\n",
    "  url = inputs[\"url\"]\n",
    "  loader = WebBaseLoader([url])\n",
    "  docs = loader.load()\n",
    "  text = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "  return text\n",
    "\n",
    "def save_to_text(inputs):\n",
    "  filename = inputs[\"filename\"]\n",
    "  text = inputs[\"text\"]\n",
    "  os.makedirs(\"./research_results\", exist_ok=True)\n",
    "  if not filename.endswith('.txt'):\n",
    "      filename += '.txt'\n",
    "  file_path = os.path.join(\"./research_results\", filename)\n",
    "  with open(file_path, 'w', encoding='utf-8') as f:\n",
    "      f.write(text)\n",
    "  return f\"Research results saved to {file_path}\"  \n",
    "\n",
    "functions = [\n",
    "  {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"duckduckgo_search\",\n",
    "        \"description\": \"Use this tool to perform web searches using the DuckDuckGo search engine. It takes a query as an argument. Example query: 'Latest technology news'\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The query you will search for\",\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"query\"],\n",
    "        },\n",
    "    },\n",
    "  },\n",
    "  {\n",
    "    \"type\": \"function\",\n",
    "      \"function\": {\n",
    "          \"name\": \"wikipedia_search\",\n",
    "          \"description\": \"Use this tool to perform searches on Wikipedia. It takes a query as an argument. Example query: 'Artificial Intelligence'\",\n",
    "          \"parameters\": {\n",
    "              \"type\": \"object\",\n",
    "              \"properties\": {\n",
    "                  \"query\": {\n",
    "                      \"type\": \"string\",\n",
    "                      \"description\": \"The query you will search for on Wikipedia\",\n",
    "                  }\n",
    "              },\n",
    "              \"required\": [\"query\"],\n",
    "          },\n",
    "      },\n",
    "\n",
    "  },\n",
    "  {\n",
    "    \"type\": \"function\",\n",
    "      \"function\": {\n",
    "          \"name\": \"web_scraping\",\n",
    "          \"description\": \"If you found the website link in DuckDuckGo, Use this to get the content of the link for my research.\",\n",
    "          \"parameters\": {\n",
    "              \"type\": \"object\",\n",
    "              \"properties\": {\n",
    "                  \"url\": {\n",
    "                      \"type\": \"string\",\n",
    "                      \"description\": \"The URL of the website you want to scrape\",\n",
    "                  }\n",
    "              },\n",
    "              \"required\": [\"url\"],\n",
    "          },\n",
    "      },\n",
    "\n",
    "  },\n",
    "  {\n",
    "      \"type\": \"function\",\n",
    "      \"function\": {\n",
    "          \"name\": \"save_to_text\",\n",
    "          \"description\": \"Use this tool to save the content as a .txt file.\",\n",
    "          \"parameters\": {\n",
    "              \"type\": \"object\",\n",
    "              \"properties\": {\n",
    "                  \"filename\": {\n",
    "                      \"type\": \"string\",\n",
    "                      \"description\": \"a name of the file you will save the research results\",\n",
    "                  },\n",
    "                  \"text\": {\n",
    "                      \"type\": \"string\",\n",
    "                      \"description\": \"The text you will save to a file.\",\n",
    "                  }\n",
    "              },\n",
    "              \"required\": [\"text\"],\n",
    "          },\n",
    "      },\n",
    "\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "assistant_id = \"asst_Non2tRgu3rvBrRrnS8qHGRny\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Thread(id='thread_GoGXf2jRFR3LZZnN8GgbPkxn', created_at=1746862551, metadata={}, object='thread', tool_resources=ToolResources(code_interpreter=None, file_search=None))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thread = client.beta.threads.create(\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\":\"user\",\n",
    "      \"content\": \"Research about the XZ backdoor\",\n",
    "    }\n",
    "  ]\n",
    ")\n",
    "thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Run(id='run_siJ6pyLoakejV1G32Tm8outx', assistant_id='asst_Non2tRgu3rvBrRrnS8qHGRny', cancelled_at=None, completed_at=None, created_at=1746863484, expires_at=1746864084, failed_at=None, incomplete_details=None, instructions='\\n        You are a research expert.\\n\\n        Your task is to use Wikipedia or DuckDuckGo to gather comprehensive and accurate information about the query provided. \\n\\n        When you find a relevant website through DuckDuckGo, you must scrape the content from that website. Use this scraped content to thoroughly research and formulate a detailed answer to the question. \\n\\n        Combine information from Wikipedia, DuckDuckGo searches, and any relevant websites you find. Ensure that the final answer is well-organized and detailed, and include citations with links (URLs) for all sources used.\\n\\n        Your research should be saved to a .txt file, and the content should match the detailed findings provided. Make sure to include all sources and relevant information.\\n\\n        The information from Wikipedia must be included.\\n\\n        Ensure that the final .txt file contains detailed information, all relevant sources, and citations.\\n        ', last_error=None, max_completion_tokens=None, max_prompt_tokens=None, metadata={}, model='gpt-3.5-turbo-1106', object='thread.run', parallel_tool_calls=True, required_action=None, response_format='auto', started_at=None, status='queued', thread_id='thread_GoGXf2jRFR3LZZnN8GgbPkxn', tool_choice='auto', tools=[FunctionTool(function=FunctionDefinition(name='duckduckgo_search', description=\"Use this tool to perform web searches using the DuckDuckGo search engine. It takes a query as an argument. Example query: 'Latest technology news'\", parameters={'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'The query you will search for'}}, 'required': ['query']}, strict=False), type='function'), FunctionTool(function=FunctionDefinition(name='wikipedia_search', description=\"Use this tool to perform searches on Wikipedia. It takes a query as an argument. Example query: 'Artificial Intelligence'\", parameters={'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'The query you will search for on Wikipedia'}}, 'required': ['query']}, strict=False), type='function'), FunctionTool(function=FunctionDefinition(name='web_scraping', description='If you found the website link in DuckDuckGo, Use this to get the content of the link for my research.', parameters={'type': 'object', 'properties': {'url': {'type': 'string', 'description': 'The URL of the website you want to scrape'}}, 'required': ['url']}, strict=False), type='function'), FunctionTool(function=FunctionDefinition(name='save_to_text', description='Use this tool to save the content as a .txt file.', parameters={'type': 'object', 'properties': {'filename': {'type': 'string', 'description': 'a name of the file you will save the research results'}, 'text': {'type': 'string', 'description': 'The text you will save to a file.'}}, 'required': ['text']}, strict=False), type='function')], truncation_strategy=TruncationStrategy(type='auto', last_messages=None), usage=None, temperature=1.0, top_p=1.0, tool_resources={}, reasoning_effort=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = client.beta.threads.runs.create(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant_id,\n",
    ")\n",
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run(run_id, thread_id):\n",
    "  return client.beta.threads.runs.retrieve(\n",
    "    run_id=run_id,\n",
    "    thread_id=thread_id,\n",
    "  )\n",
    "\n",
    "def get_messages(thread_id):\n",
    "  messages = client.beta.threads.messages.list(thread_id=thread_id)\n",
    "  messages = list(messages)\n",
    "  messages.reverse()\n",
    "  for message in messages:\n",
    "    print(f\"{message.role}: {message.content[0].text.value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Run(id='run_siJ6pyLoakejV1G32Tm8outx', assistant_id='asst_Non2tRgu3rvBrRrnS8qHGRny', cancelled_at=None, completed_at=None, created_at=1746863484, expires_at=1746864084, failed_at=None, incomplete_details=None, instructions='\\n        You are a research expert.\\n\\n        Your task is to use Wikipedia or DuckDuckGo to gather comprehensive and accurate information about the query provided. \\n\\n        When you find a relevant website through DuckDuckGo, you must scrape the content from that website. Use this scraped content to thoroughly research and formulate a detailed answer to the question. \\n\\n        Combine information from Wikipedia, DuckDuckGo searches, and any relevant websites you find. Ensure that the final answer is well-organized and detailed, and include citations with links (URLs) for all sources used.\\n\\n        Your research should be saved to a .txt file, and the content should match the detailed findings provided. Make sure to include all sources and relevant information.\\n\\n        The information from Wikipedia must be included.\\n\\n        Ensure that the final .txt file contains detailed information, all relevant sources, and citations.\\n        ', last_error=None, max_completion_tokens=None, max_prompt_tokens=None, metadata={}, model='gpt-3.5-turbo-1106', object='thread.run', parallel_tool_calls=True, required_action=RequiredAction(submit_tool_outputs=RequiredActionSubmitToolOutputs(tool_calls=[RequiredActionFunctionToolCall(id='call_nXNhGlFMnQCAoKNRScDJiDUv', function=Function(arguments='{\"query\": \"XZ backdoor\"}', name='wikipedia_search'), type='function'), RequiredActionFunctionToolCall(id='call_iP1bEosQnlEfzvUSc9V55LvH', function=Function(arguments='{\"query\": \"XZ backdoor\"}', name='duckduckgo_search'), type='function')]), type='submit_tool_outputs'), response_format='auto', started_at=1746863486, status='requires_action', thread_id='thread_GoGXf2jRFR3LZZnN8GgbPkxn', tool_choice='auto', tools=[FunctionTool(function=FunctionDefinition(name='duckduckgo_search', description=\"Use this tool to perform web searches using the DuckDuckGo search engine. It takes a query as an argument. Example query: 'Latest technology news'\", parameters={'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'The query you will search for'}}, 'required': ['query']}, strict=False), type='function'), FunctionTool(function=FunctionDefinition(name='wikipedia_search', description=\"Use this tool to perform searches on Wikipedia. It takes a query as an argument. Example query: 'Artificial Intelligence'\", parameters={'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'The query you will search for on Wikipedia'}}, 'required': ['query']}, strict=False), type='function'), FunctionTool(function=FunctionDefinition(name='web_scraping', description='If you found the website link in DuckDuckGo, Use this to get the content of the link for my research.', parameters={'type': 'object', 'properties': {'url': {'type': 'string', 'description': 'The URL of the website you want to scrape'}}, 'required': ['url']}, strict=False), type='function'), FunctionTool(function=FunctionDefinition(name='save_to_text', description='Use this tool to save the content as a .txt file.', parameters={'type': 'object', 'properties': {'filename': {'type': 'string', 'description': 'a name of the file you will save the research results'}, 'text': {'type': 'string', 'description': 'The text you will save to a file.'}}, 'required': ['text']}, strict=False), type='function')], truncation_strategy=TruncationStrategy(type='auto', last_messages=None), usage=None, temperature=1.0, top_p=1.0, tool_resources={}, reasoning_effort=None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_run(run.id, thread.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: Research about the XZ backdoor\n"
     ]
    }
   ],
   "source": [
    "get_messages(thread.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fullstackgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
